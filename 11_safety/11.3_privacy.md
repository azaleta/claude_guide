## 11.3 数据隐私与合规 (Data Privacy & Compliance)

在将 AI 引入生产环境之前，CTO 和法务部门最关心的问题通常不是"它够不够聪明"，而是"它会不会泄密"。本节将详细介绍 Anthropic 的数据政策以及企业级隐私保护最佳实践。

### 11.3.1 商业数据归属权

Anthropic 官方（截至 2026 年）对于 API 数据的政策极其明确：

> **Your Data is Yours.**
> data submitted to the API is **NOT** used to train Anthropic's models.

这与 ChatGPT 的免费版（数据默认用于训练）有本质区别。
对于商业 API 用户 (Tier 1+)，Anthropic 承诺零数据留存用于训练。这使得它符合大多数企业的采购标准。

值得注意的是，这一政策适用于 **API 调用**，而非 claude.ai 网页版的免费用户。如果企业对数据隐私有严格要求，务必使用 API 或 Claude for Enterprise 方案。

### 11.3.2 数据留存期 (Data Retention)

虽然不用于训练，但在服务器上会保留多久用于 Debug？
*   **默认**: 30 天（用于反滥用监测）。
*   **Zero Retention**: 对于处理极度敏感数据（医疗、金融）的企业，可以申请"零留存"协议。API 请求处理完毕后，不仅没用于训练，连 Log 里的记录也会即刻粉碎。

### 11.3.3 合规性认证

Anthropic 平台已通过多项国际认证：
*   **SOC 2 Type II**: 证明其在安全性、可用性、保密性方面的控制措施有效。
*   **HIPAA Compliance**: 符合美国医疗数据保护法案（需签署 BAA）。
*   **GDPR**: 符合欧盟通用数据保护条例。
*   **CCPA**: 符合加州消费者隐私保护法案。

对于需要在特定地区运营的企业，Anthropic 还提供区域化部署选项，确保数据不跨境传输。

### 11.3.4 最佳实践：企业级数据处理

#### 数据最小化 (Data Minimization)
只发送 LLM 解题必须的数据。
*   *Bad*: 发送整个 User Profile JSON 对象（包含地址、电话、信用卡号）。
*   *Good*: 只发送 `{"user_name": "Alice", "recent_purchase": "Book"}`。

#### 本地匿名化 (Local Anonymization)
在数据离开私有云（Private VPC）之前，对其进行脱敏。
使用 **Faker** 或哈希算法：
*   `Alice Smith` -> `User_A7B2`
*   `192.168.1.1` -> `[IP_ADDRESS]`

当 Claude 返回结果后，再在本地进行**反向替换 (De-anonymization)**，还原出真实信息呈现给用户。这样，真实的 PII 永远不会离开内网。

**示例代码**：

```python
import re

PII_PATTERNS = {
    r'\b\d{3}-\d{2}-\d{4}\b': '[SSN]',  # 社会安全号
    r'\b\d{16}\b': '[CREDIT_CARD]',      # 信用卡号
    r'[\w\.-]+@[\w\.-]+': '[EMAIL]',     # 电子邮件
}

def anonymize(text):
    for pattern, placeholder in PII_PATTERNS.items():
        text = re.sub(pattern, placeholder, text)
    return text
```

#### 审计日志 (Audit Trails)
记录每一次 LLM 调用的元数据（Metadata），但不记录 Payload。
*   Who: 哪个员工调用的？
*   When: 时间戳。
*   Cost: 消耗了多少 Token？
*   Subject: 大致主题是什么（由分类器打标，而非原文）。

#### 访问控制 (Access Control)
实施基于角色的访问控制（RBAC），确保只有授权人员可以访问 Claude API：
*   开发环境使用独立的 API Key
*   生产环境的 Key 存储在 Secret Manager 中
*   定期轮换 API Key

---

安全和隐私是底线。但作为 AI 开发者，还要承担更高的社会责任。
AI 是否有偏见？AI 是否会剥夺工作机会？如何构建一个**负责任**的 AI 系统？

➡️ [负责任的 AI 应用](11.4_responsible.md)
